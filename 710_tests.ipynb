{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from multiprocessing import Process\n",
    "import download_read\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PARALLELIZE DOWNLOADS  ##########\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "foods = ['tuna', 'rice', 'pear', 'apple', 'coffee', 'lettuce', 'beans']\n",
    "hazards = 'storm' #, ['drought', 'heatwave', 'warming', 'storm', 'flooding']\n",
    "scholar_pages = [1]\n",
    "scholar_results = 3\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # create all tasks\n",
    "    processes = [Process(target=download_read.download_papers, args=(foods[i],hazards, scholar_pages, scholar_results, True)) for i in range(7)]\n",
    "    # start all processes\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "    # wait for all processes to complete\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    # report that all tasks are completed\n",
    "    print('Done', flush=True)\n",
    "\n",
    "end_time = time.time() #stop timer\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "# Anna: 3:03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PARALLELIZE DOWNLOADS for food and hazard... ##########\n",
    "start_time = time.time()\n",
    "\n",
    "foods = ['tuna', 'rice', 'pear', 'apple', 'coffee', 'lettuce', 'beans']\n",
    "hazards = ['storm', 'drought', 'heatwave'] #, 'warming', 'storm', 'flooding']\n",
    "scholar_pages = [1]\n",
    "scholar_results = 3\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # create all tasks\n",
    "    processes = [Process(target=download_read.download_papers, args=(food, hazard, scholar_pages, scholar_results, True)) for food in foods for hazard in hazards]\n",
    "    # start all processes\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "    # wait for all processes to complete\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    # report that all tasks are completed\n",
    "    print('Done', flush=True)\n",
    "\n",
    "end_time = time.time() #stop timer\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "## Anna: 7:33 - saves a little time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TIMER COMPARISON AGAINST NON-PARALLEL PROCESSING\n",
    "start = time.time()\n",
    "\n",
    "foods = ['tuna']#, 'pear', 'apple', 'coffee', 'lettuce', 'beans']\n",
    "hazards = 'storm' #, ['drought', 'heatwave', 'warming', 'storm', 'flooding']\n",
    "scholar_pages = [1]\n",
    "scholar_results = 1\n",
    "\n",
    "for food in foods:\n",
    "    download_read.download_papers(food, hazards, scholar_pages, scholar_results, True)\n",
    "\n",
    "stop = time.time() #stop timer\n",
    "timelength = stop - start\n",
    "print(timelength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test against human annotated papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = ['Bay leaf','Bignose unicornfish','Button mushroom','Centropristis philadelphica','Chinese softshell turtle','Corica soborna','Ganges river sprat','Grasshopper','Large yellow croaker','Larimichthys croceus','Leucoraja erinacea','Little skate','mealworm','Naso vlamingii','Orange-spotted grouper','Ordways brotula','Pusa hispida','Ringed seal','Rock sea bass','Tenebrio molitor','Trionyx sinensis','Triticum aestivum','wheat']\n",
    "hazards = ['atmospheric CO2 increases','ocean acidification','ozone','storms','warming','precipitation','precipitation','fires','warming','warming','ocean acidification','ocean acidification','warming','ocean acidification','natural cover change','floods','heatwaves','Heatwaves','storms','warming','warming','drought','drought']\n",
    "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
    "scholar_pages = [1,2]\n",
    "scholar_results = 10\n",
    "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
    "\n",
    "dfall = pd.DataFrame(columns=['filename', 'food', 'hazard', 'quote', 'location', 'pos/neg', 'how']) ## Specify a question in quotes or use the default: \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
    "\n",
    "##### not working because it needs a list? argument ######... put 'None'\n",
    "for i in range(len(foods)):\n",
    "    df = download_read.download_read_export(None, foods[i], hazards[i], API_Key, scholar_pages, scholar_results, question, True)\n",
    "    dfall = pd.concat([dfall, df], ignore_index=True)\n",
    "\n",
    "dfall # much easier to view without print statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = ['Bay leaf','Bignose unicornfish','Button mushroom','Centropristis philadelphica','Chinese softshell turtle','Corica soborna','Ganges river sprat','Grasshopper','Large yellow croaker','Larimichthys croceus','Leucoraja erinacea','Little skate','mealworm','Naso vlamingii','Orange-spotted grouper','Ordways brotula','Pusa hispida','Ringed seal','Rock sea bass','Tenebrio molitor','Trionyx sinensis','Triticum aestivum','wheat']\n",
    "hazards = ['atmospheric CO2 increases','ocean acidification','ozone','storms','warming','precipitation','precipitation','fires','warming','warming','ocean acidification','ocean acidification','warming','ocean acidification','natural cover change','floods','heatwaves','Heatwaves','storms','warming','warming','drought','drought']\n",
    "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
    "scholar_pages = [1,2]\n",
    "scholar_results = 10\n",
    "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
    "\n",
    "for i in range(12,len(foods)):\n",
    "    df = download_read.download_read_export(foods[i], hazards[i], API_Key, scholar_pages, scholar_results, question, True)\n",
    "    dfall = pd.concat([dfall, df], ignore_index=True)\n",
    "\n",
    "dfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.to_csv('testdataentry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test import csv foodlist\n",
    "\n",
    "foodlist = download_read.import_foodlist(\"Test food items.csv\")\n",
    "foodlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is just minor but it often breaks if you use a datatype (list) as a variable.. then we cant use 'list' to make lists\n",
    "for namegroup in foodlist: \n",
    "    print(f\"{namegroup}\")\n",
    "    print(foodlist[namegroup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test list split to different columns and run all functions\n",
    "import download_read\n",
    "from multiprocessing import Process\n",
    "\n",
    "foodlist = download_read.import_foodlist(\"Test food items.csv\")\n",
    "hazards = ['Warming','Atmospheric CO2 Increase','Ocean Acidification','Drought','Precipitation','Storms','Ozone','Fires','Sea level rise','Floods','Heatwaves','Natural cover change']\n",
    "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
    "scholar_pages = [1,2]\n",
    "scholar_results = 10\n",
    "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
    "\n",
    "for hazard in hazards:\n",
    "   for list in foodlist:\n",
    "      foods = foodlist[list]\n",
    "      if __name__ == '__main__':\n",
    "            # create all tasks\n",
    "            processes = [Process(target=download_read.download_papers, args=(foods[i],hazard, scholar_pages, scholar_results, True)) for i in range(len(foods))]\n",
    "            # start all processes\n",
    "            for process in processes:\n",
    "                process.start()\n",
    "            # wait for all processes to complete\n",
    "            for process in processes:\n",
    "                process.join()\n",
    "            # report that all tasks are completed\n",
    "            print('Done', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import download_read\n",
    "import pandas as pd\n",
    "\n",
    "foodlist = download_read.import_foodlist(\"Test food items.csv\")\n",
    "hazards = ['Warming','Atmospheric CO2 Increase','Ocean Acidification','Drought','Precipitation','Storms','Ozone','Fires','Sea level rise','Floods','Heatwaves','Natural cover change']\n",
    "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
    "scholar_pages = [1,2]\n",
    "scholar_results = 10\n",
    "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
    "\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "dfall = pd.DataFrame(columns=['filename', 'foodname','species','othername', 'hazard', 'quote', 'location', 'pos/neg', 'how','howquote']) ## Specify a question in quotes or use the default: \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
    "skip_if_folder_exists = True ## dummy variable, if you have the data downloaded already and dont want to re-download it. defualt=True\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "#dfall = pd.DataFrame(columns=['food', 'hazard', 'quote', 'location', 'page', 'paragraph'])\n",
    "\n",
    "## Run function across combinations of food and hazard\n",
    "for hazard in hazards:\n",
    "   for list in foodlist:\n",
    "      foods = foodlist[list]\n",
    "      for food in foods:\n",
    "         df = download_read.upload_analyze_papers(list,food, hazard, pdfs, API_Key, question='default')\n",
    "         dfall = pd.concat([dfall, df], ignore_index=True)\n",
    "\n",
    "# Print the merged dataframe\n",
    "print(dfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os: /Users/reneesetter/Food/cliffs\n",
      "starting bot 2...\n",
      "Query: corn drought\n",
      "\n",
      "Google Scholar page 1 : 1 papers found\n",
      "Searching paper 1 of 1 on Crossref...\n",
      "papers What happens within the corn plant when drought occurs\n",
      "Papers found on Crossref: 0/1\n",
      "\n",
      "Already downloaded all files\n",
      "downloaded 1 of 1 papers\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from PyPaperBot2 import __main__ as p\n",
    "import os\n",
    "import glob\n",
    "\n",
    "## test download - what happens with repeat pdfs ###\n",
    "print(\"os:\", os.getcwd())\n",
    "food = 'corn'\n",
    "hazard = 'drought'\n",
    "scholar_pages = [1]\n",
    "scholar_results = 1\n",
    "dwn_dir = os.getcwd() + \"/papers/\"\n",
    "\n",
    "# Create papers directory \n",
    "os.makedirs(dwn_dir, exist_ok=True)\n",
    "\n",
    "# Make the query:\n",
    "query = f'{food} {hazard}'\n",
    "# Download papers from Google Scholar\n",
    "p.start(query=query, scholar_pages=scholar_pages, scholar_results=scholar_results, dwn_dir=dwn_dir, proxy=[])\n",
    "\n",
    "pdfs = glob.glob(os.path.join(dwn_dir, '*.pdf'))\n",
    "print('downloaded %d of %d papers' % (len(pdfs), scholar_results))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting bot 2...\n",
      "Query: spotted rose snapper Warming\n",
      "starting bot 2...\n",
      "Query: maize Warming\n",
      "\n",
      "Google Scholar page 1 : 5 papers found\n",
      "Searching paper 1 of 5 on Crossref...\n",
      "\n",
      "Google Scholar page 1 : 5 papers found\n",
      "Searching paper 1 of 5 on Crossref...\n",
      "Searching paper 2 of 5 on Crossref...\n",
      "Searching paper 2 of 5 on Crossref...\n",
      "Searching paper 3 of 5 on Crossref...\n",
      "Searching paper 4 of 5 on Crossref...\n",
      "Searching paper 3 of 5 on Crossref...\n",
      "Searching paper 5 of 5 on Crossref...\n",
      "Searching paper 4 of 5 on Crossref...\n",
      "Searching paper 5 of 5 on Crossref...\n",
      "papers Characterizing Potential Responses to Warming of Mexican Marine Resources in Tropical Atlantic and Pacific Regions Based on Their Thermal Niche\n",
      "Papers found on Crossref: 4/5\n",
      "\n",
      "\n",
      "Using https://sci-hub.ee as Sci-Hub instance\n",
      "Download 1 of 5 -> Characterizing Potential Responses to Warming of Mexican Marine Resources in Tropical Atlantic and Pacific Regions Based on Their Thermal Niche\n",
      "papers Global warming presents new challenges for maize pest management\n",
      "Papers found on Crossref: 5/5\n",
      "\n",
      "\n",
      "Using https://sci-hub.ee as Sci-Hub instance\n",
      "Download 1 of 5 -> Global warming presents new challenges for maize pest management\n",
      "Download 2 of 5 -> Future warming increases probability of globally synchronized maize production shocks\n",
      "Download 3 of 5 -> Global warming and increasing maize cultivation demand comprehensive efforts in disease and insect resistance breeding in north‐western Europe\n",
      "Download 4 of 5 -> The benefits of recent warming for maize production in high latitude China\n",
      "Download 2 of 5 -> Parasite communities of the spotted rose snapper Lutjanus guttatus (Perciformes: Lutjanidae) off the Mexican Pacific coasts: Spatial and long-term inter-annual …\n",
      "Download 5 of 5 -> High-yield maize with large net energy yield and small global warming intensity\n",
      "downloaded 6 of 5 papers\n",
      "Done\n",
      "Download 3 of 5 -> The Ecological and Anthropogenic Impacts of fishing gear in a tropical system: How the size of Spotted Rose Snapper (Lutjanus guttatus) and the ratio of target catch …\n",
      "Download 4 of 5 -> Regional Correspondence in Habitat Occupancy by Gray Snapper (Lutjanus griseus) in Estuaries of the Southeastern United States\n",
      "Download 5 of 5 -> Climate‐related, decadal‐scale assemblage changes of seagrass‐associated fishes in the northern Gulf of Mexico\n",
      "downloaded 9 of 5 papers\n",
      "Done\n",
      "Done\n",
      "starting bot 2...\n",
      "starting bot 2...Query: Lutjanus guttatus Warming\n",
      "Query: Zea mays Warming\n",
      "\n",
      "\n",
      "Google Scholar page 1 : 5 papers found\n",
      "Searching paper 1 of 5 on Crossref...\n",
      "\n",
      "Google Scholar page 1 : 5 papers found\n",
      "Searching paper 1 of 5 on Crossref...\n",
      "Searching paper 2 of 5 on Crossref...\n",
      "Searching paper 2 of 5 on Crossref...\n",
      "Searching paper 3 of 5 on Crossref...\n",
      "Searching paper 3 of 5 on Crossref...\n",
      "Searching paper 4 of 5 on Crossref...\n",
      "Searching paper 5 of 5 on Crossref...\n",
      "Searching paper 4 of 5 on Crossref...\n",
      "Searching paper 5 of 5 on Crossref...\n",
      "papers Effects of artificial warming on the structural, physiological, and biochemical changes of maize (Zea mays L.) leaves in northern China\n",
      "Papers found on Crossref: 5/5\n",
      "\n",
      "\n",
      "Using https://sci-hub.ee as Sci-Hub instance\n",
      "Download 1 of 5 -> Effects of artificial warming on the structural, physiological, and biochemical changes of maize (Zea mays L.) leaves in northern China\n",
      "papers … acclimation temperature on thermoregulatory behaviour, thermal tolerance and respiratory metabolism of Lutjanus guttatus and the response of heat shock protein 70 …\n",
      "Papers found on Crossref: 4/5\n",
      "\n",
      "Download 2 of 5 -> Warming and elevated CO2 alter the transcriptomic response of maize (Zea mays L.) at the silking stage\n",
      "\n",
      "Using https://sci-hub.ee as Sci-Hub instance\n",
      "Download 1 of 5 -> … acclimation temperature on thermoregulatory behaviour, thermal tolerance and respiratory metabolism of Lutjanus guttatus and the response of heat shock protein 70 …\n",
      "Download 3 of 5 -> Temperature Responses of Photosynthesis and Respiration of Maize (Zea mays) Plants to Experimental Warming\n",
      "Download 2 of 5 -> A new efficient method for the mass production of juvenile spotted rose snapper Lutjanus guttatus\n",
      "Download 4 of 5 -> Experimental warming enhances the carbon gain but does not affect the yield of maize (Zea mays L.) in the North China Plain\n",
      "Download 3 of 5 -> Parasite communities of the spotted rose snapper Lutjanus guttatus (Perciformes: Lutjanidae) off the Mexican Pacific coasts: Spatial and long-term inter-annual …\n",
      "Download 5 of 5 -> Effective hybrids of Zea mays L. under conditions of changes in the boundaries of agro-climatic zones under the influence of global warming\n",
      "Download 4 of 5 -> … effect of substituting fish meal with soybean meal on growth, feed efficiency, body composition and blood chemistry in juvenile spotted rose snapper Lutjanus guttatus …\n",
      "downloaded 16 of 5 papers\n",
      "Done\n",
      "Download 5 of 5 -> Expression and activity of trypsin and pepsin during larval development of the spotted rose snapper Lutjanus guttatus\n",
      "downloaded 18 of 5 papers\n",
      "Done\n",
      "Done\n",
      "starting bot 2...\n",
      "Query: popcorn Warmingstarting bot 2...\n",
      "\n",
      "Query: corn Warming\n",
      "\n",
      "Google Scholar page 1 : 5 papers found\n",
      "Searching paper 1 of 5 on Crossref...\n",
      "\n",
      "Google Scholar page 1 : 5 papers found\n",
      "Searching paper 1 of 5 on Crossref...\n",
      "Searching paper 2 of 5 on Crossref...\n",
      "Searching paper 2 of 5 on Crossref...\n",
      "Searching paper 3 of 5 on Crossref...\n",
      "Searching paper 3 of 5 on Crossref...\n",
      "Searching paper 4 of 5 on Crossref...\n",
      "Searching paper 4 of 5 on Crossref...\n",
      "Searching paper 5 of 5 on Crossref...\n",
      "papers Response of corn to climate warming in arid areas in Northwest China\n",
      "Papers found on Crossref: 4/5\n",
      "\n",
      "\n",
      "Using https://sci-hub.ee as Sci-Hub instance\n",
      "Download 1 of 5 -> Response of corn to climate warming in arid areas in Northwest China\n",
      "Searching paper 5 of 5 on Crossref...\n",
      "Download 2 of 5 -> Long‐term no‐till and stover retention each decrease the global warming potential of irrigated continuous corn\n",
      "Download 3 of 5 -> New biological model to manage the impact of climate warming on maize corn borers\n",
      "papers The physics of popping popcorn\n",
      "Papers found on Crossref: 5/5\n",
      "\n",
      "\n",
      "Using https://sci-hub.ee as Sci-Hub instance\n",
      "Download 1 of 5 -> The physics of popping popcorn\n",
      "Download 4 of 5 -> Do mitigation strategies reduce global warming potential in the northern US corn belt?\n",
      "Download 2 of 5 -> Ruining popcorn? The welfare effects of information\n",
      "Download 5 of 5 -> Spatially and temporally explicit life cycle global warming, eutrophication, and acidification impacts from corn production in the US Midwest\n",
      "Download 3 of 5 -> Popcorn: critical temperature, jump and sound\n",
      "downloaded 24 of 5 papers\n",
      "Done\n",
      "Download 4 of 5 -> Chilled versus ambient aeration and fumigation of stored popcorn Part 1: Temperature management\n",
      "Download 5 of 5 -> Mulberry popcorn disease occurrence in Korea region and development of integrative control method.\n",
      "downloaded 27 of 5 papers\n",
      "Done\n",
      "Done\n",
      "263.6143379211426\n"
     ]
    }
   ],
   "source": [
    "### TEST CSV IMPORT, PARALLELIZED FOOD & HAZARD, REPEATED DOWNLOADS\n",
    "\n",
    "#test list split to different columns and run all functions\n",
    "from PyPaperBot2 import __main__ as p\n",
    "import os\n",
    "import glob\n",
    "import download_read\n",
    "from multiprocessing import Process\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "foodlist = download_read.import_foodlist(\"testlist.csv\")\n",
    "hazards = ['Warming']#,'Atmospheric CO2 Increase','Ocean Acidification','Drought'] #,'Precipitation','Storms','Ozone','Fires','Sea level rise','Floods','Heatwaves','Natural cover change']\n",
    "scholar_pages = [1]\n",
    "scholar_results = 5\n",
    "\n",
    "for l in foodlist:\n",
    "   foods = foodlist[l]\n",
    "   if __name__ == '__main__':\n",
    "        # create all tasks\n",
    "        processes = [Process(target=download_read.download_papers, args=(food,hazard, scholar_pages, scholar_results, True)) for food in foods for hazard in hazards]\n",
    "        # start all processes\n",
    "        for process in processes:\n",
    "            process.start()\n",
    "        # wait for all processes to complete\n",
    "        for process in processes:\n",
    "            process.join()\n",
    "        # report that all tasks are completed\n",
    "        print('Done', flush=True)\n",
    "\n",
    "end_time = time.time() #stop timer\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import download_read\n",
    "\n",
    "dfall = pd.DataFrame(columns=['filename', 'foodname','species','othername', 'hazard', 'quote', 'location', 'pos/neg', 'how','howquote']) ## Specify a question in quotes or use the default: \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
    "foodlist = download_read.import_foodlist(\"Test food items.csv\")\n",
    "hazards = ['Warming','Atmospheric CO2 Increase','Ocean Acidification','Drought','Precipitation','Storms','Ozone','Fires','Sea level rise','Floods','Heatwaves','Natural cover change']\n",
    "\n",
    "\n",
    "for hazard in hazards:\n",
    "   for list in foodlist:\n",
    "        foods = foodlist[list]\n",
    "        for food in foods:\n",
    "            row_data = {\n",
    "                'filename': 'x',\n",
    "                list: food,\n",
    "                'hazard': hazard,\n",
    "                'quote': 'quote',\n",
    "                'location': 'location',\n",
    "                'pos/neg': 'posneg',\n",
    "                'how': 'how',\n",
    "                'howquote': 'howquote'\n",
    "            }\n",
    "\n",
    "                # Append the row data to the results\n",
    "            dfall = pd.concat([dfall, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "dfall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
