{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from multiprocessing import Process\n",
    "import download_read\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PARALLELIZE DOWNLOADS  ##########\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "foods = ['tuna', 'rice', 'pear', 'apple', 'coffee', 'lettuce', 'beans']\n",
    "hazards = 'storm' #, ['drought', 'heatwave', 'warming', 'storm', 'flooding']\n",
    "scholar_pages = [1]\n",
    "scholar_results = 3\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # create all tasks\n",
    "    processes = [Process(target=download_read.download_papers, args=(foods[i],hazards, scholar_pages, scholar_results, True)) for i in range(7)]\n",
    "    # start all processes\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "    # wait for all processes to complete\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    # report that all tasks are completed\n",
    "    print('Done', flush=True)\n",
    "\n",
    "end_time = time.time() #stop timer\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "# Anna: 3:03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### PARALLELIZE DOWNLOADS for food and hazard... ##########\n",
    "start_time = time.time()\n",
    "\n",
    "foods = ['tuna', 'rice', 'pear', 'apple', 'coffee', 'lettuce', 'beans']\n",
    "hazards = ['storm', 'drought', 'heatwave'] #, 'warming', 'storm', 'flooding']\n",
    "scholar_pages = [1]\n",
    "scholar_results = 3\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # create all tasks\n",
    "    processes = [Process(target=download_read.download_papers, args=(food, hazard, scholar_pages, scholar_results, True)) for food in foods for hazard in hazards]\n",
    "    # start all processes\n",
    "    for process in processes:\n",
    "        process.start()\n",
    "    # wait for all processes to complete\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "    # report that all tasks are completed\n",
    "    print('Done', flush=True)\n",
    "\n",
    "end_time = time.time() #stop timer\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "## Anna: 7:33 - saves a little time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TIMER COMPARISON AGAINST NON-PARALLEL PROCESSING\n",
    "start = time.time()\n",
    "\n",
    "foods = ['tuna']#, 'pear', 'apple', 'coffee', 'lettuce', 'beans']\n",
    "hazards = 'storm' #, ['drought', 'heatwave', 'warming', 'storm', 'flooding']\n",
    "scholar_pages = [1]\n",
    "scholar_results = 1\n",
    "\n",
    "for food in foods:\n",
    "    download_read.download_papers(food, hazards, scholar_pages, scholar_results, True)\n",
    "\n",
    "stop = time.time() #stop timer\n",
    "timelength = stop - start\n",
    "print(timelength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test against human annotated papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = ['Bay leaf','Bignose unicornfish','Button mushroom','Centropristis philadelphica','Chinese softshell turtle','Corica soborna','Ganges river sprat','Grasshopper','Large yellow croaker','Larimichthys croceus','Leucoraja erinacea','Little skate','mealworm','Naso vlamingii','Orange-spotted grouper','Ordways brotula','Pusa hispida','Ringed seal','Rock sea bass','Tenebrio molitor','Trionyx sinensis','Triticum aestivum','wheat']\n",
    "hazards = ['atmospheric CO2 increases','ocean acidification','ozone','storms','warming','precipitation','precipitation','fires','warming','warming','ocean acidification','ocean acidification','warming','ocean acidification','natural cover change','floods','heatwaves','Heatwaves','storms','warming','warming','drought','drought']\n",
    "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
    "scholar_pages = [1,2]\n",
    "scholar_results = 10\n",
    "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
    "\n",
    "dfall = pd.DataFrame(columns=['filename', 'food', 'hazard', 'quote', 'location', 'pos/neg', 'how']) ## Specify a question in quotes or use the default: \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
    "\n",
    "##### not working because it needs a list? argument ######... put 'None'\n",
    "for i in range(len(foods)):\n",
    "    df = download_read.download_read_export(None, foods[i], hazards[i], API_Key, scholar_pages, scholar_results, question, True)\n",
    "    dfall = pd.concat([dfall, df], ignore_index=True)\n",
    "\n",
    "dfall # much easier to view without print statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foods = ['Bay leaf','Bignose unicornfish','Button mushroom','Centropristis philadelphica','Chinese softshell turtle','Corica soborna','Ganges river sprat','Grasshopper','Large yellow croaker','Larimichthys croceus','Leucoraja erinacea','Little skate','mealworm','Naso vlamingii','Orange-spotted grouper','Ordways brotula','Pusa hispida','Ringed seal','Rock sea bass','Tenebrio molitor','Trionyx sinensis','Triticum aestivum','wheat']\n",
    "hazards = ['atmospheric CO2 increases','ocean acidification','ozone','storms','warming','precipitation','precipitation','fires','warming','warming','ocean acidification','ocean acidification','warming','ocean acidification','natural cover change','floods','heatwaves','Heatwaves','storms','warming','warming','drought','drought']\n",
    "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
    "scholar_pages = [1,2]\n",
    "scholar_results = 10\n",
    "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
    "\n",
    "for i in range(12,len(foods)):\n",
    "    df = download_read.download_read_export(foods[i], hazards[i], API_Key, scholar_pages, scholar_results, question, True)\n",
    "    dfall = pd.concat([dfall, df], ignore_index=True)\n",
    "\n",
    "dfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall.to_csv('testdataentry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test import csv foodlist\n",
    "\n",
    "foodlist = download_read.import_foodlist(\"Test food items.csv\")\n",
    "foodlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is just minor but it often breaks if you use a datatype (list) as a variable.. then we cant use 'list' to make lists\n",
    "for namegroup in foodlist: \n",
    "    print(f\"{namegroup}\")\n",
    "    print(foodlist[namegroup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test list split to different columns and run all functions\n",
    "import download_read\n",
    "from multiprocessing import Process\n",
    "\n",
    "foodlist = download_read.import_foodlist(\"Test food items.csv\")\n",
    "hazards = ['Warming','Atmospheric CO2 Increase','Ocean Acidification','Drought','Precipitation','Storms','Ozone','Fires','Sea level rise','Floods','Heatwaves','Natural cover change']\n",
    "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
    "scholar_pages = [1,2]\n",
    "scholar_results = 10\n",
    "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
    "\n",
    "for hazard in hazards:\n",
    "   for list in foodlist:\n",
    "      foods = foodlist[list]\n",
    "      if __name__ == '__main__':\n",
    "            # create all tasks\n",
    "            processes = [Process(target=download_read.download_papers, args=(foods[i],hazard, scholar_pages, scholar_results, True)) for i in range(len(foods))]\n",
    "            # start all processes\n",
    "            for process in processes:\n",
    "                process.start()\n",
    "            # wait for all processes to complete\n",
    "            for process in processes:\n",
    "                process.join()\n",
    "            # report that all tasks are completed\n",
    "            print('Done', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import download_read\n",
    "import pandas as pd\n",
    "\n",
    "foodlist = download_read.import_foodlist(\"Test food items.csv\")\n",
    "hazards = ['Warming','Atmospheric CO2 Increase','Ocean Acidification','Drought','Precipitation','Storms','Ozone','Fires','Sea level rise','Floods','Heatwaves','Natural cover change']\n",
    "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
    "scholar_pages = [1,2]\n",
    "scholar_results = 10\n",
    "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
    "\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "dfall = pd.DataFrame(columns=['filename', 'foodname','species','othername', 'hazard', 'quote', 'location', 'pos/neg', 'how','howquote']) ## Specify a question in quotes or use the default: \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
    "skip_if_folder_exists = True ## dummy variable, if you have the data downloaded already and dont want to re-download it. defualt=True\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "#dfall = pd.DataFrame(columns=['food', 'hazard', 'quote', 'location', 'page', 'paragraph'])\n",
    "\n",
    "## Run function across combinations of food and hazard\n",
    "for hazard in hazards:\n",
    "   for list in foodlist:\n",
    "      foods = foodlist[list]\n",
    "      for food in foods:\n",
    "         df = download_read.upload_analyze_papers(list,food, hazard, pdfs, API_Key, question='default')\n",
    "         dfall = pd.concat([dfall, df], ignore_index=True)\n",
    "\n",
    "# Print the merged dataframe\n",
    "print(dfall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os: /Users/reneesetter/Food/cliffs\n",
      "starting bot 2...\n",
      "Query: corn drought\n",
      "\n",
      "Google Scholar page 1 : 1 papers found\n",
      "Searching paper 1 of 1 on Crossref...\n",
      "papers What happens within the corn plant when drought occurs\n",
      "Papers found on Crossref: 0/1\n",
      "\n",
      "Already downloaded all files\n",
      "downloaded 1 of 1 papers\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from PyPaperBot2 import __main__ as p\n",
    "import os\n",
    "import glob\n",
    "\n",
    "## test download - what happens with repeat pdfs ###\n",
    "print(\"os:\", os.getcwd())\n",
    "food = 'corn'\n",
    "hazard = 'drought'\n",
    "scholar_pages = [1]\n",
    "scholar_results = 1\n",
    "dwn_dir = os.getcwd() + \"/papers/\"\n",
    "\n",
    "# Create papers directory \n",
    "os.makedirs(dwn_dir, exist_ok=True)\n",
    "\n",
    "# Make the query:\n",
    "query = f'{food} {hazard}'\n",
    "# Download papers from Google Scholar\n",
    "p.start(query=query, scholar_pages=scholar_pages, scholar_results=scholar_results, dwn_dir=dwn_dir, proxy=[])\n",
    "\n",
    "pdfs = glob.glob(os.path.join(dwn_dir, '*.pdf'))\n",
    "print('downloaded %d of %d papers' % (len(pdfs), scholar_results))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = f'pdfs'\n",
    "dwn_dir = os.path.join(os.getcwd(), folder_name)\n",
    "dwn_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import download_read\n",
    "\n",
    "dfall = pd.DataFrame(columns=['filename', 'foodname','species','othername', 'hazard', 'quote', 'location', 'pos/neg', 'how','howquote']) ## Specify a question in quotes or use the default: \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
    "foodlist = download_read.import_foodlist(\"Test food items.csv\")\n",
    "hazards = ['Warming','Atmospheric CO2 Increase','Ocean Acidification','Drought','Precipitation','Storms','Ozone','Fires','Sea level rise','Floods','Heatwaves','Natural cover change']\n",
    "\n",
    "\n",
    "for hazard in hazards:\n",
    "   for list in foodlist:\n",
    "        foods = foodlist[list]\n",
    "        for food in foods:\n",
    "            row_data = {\n",
    "                'filename': 'x',\n",
    "                list: food,\n",
    "                'hazard': hazard,\n",
    "                'quote': 'quote',\n",
    "                'location': 'location',\n",
    "                'pos/neg': 'posneg',\n",
    "                'how': 'how',\n",
    "                'howquote': 'howquote'\n",
    "            }\n",
    "\n",
    "                # Append the row data to the results\n",
    "            dfall = pd.concat([dfall, pd.DataFrame([row_data])], ignore_index=True)\n",
    "\n",
    "dfall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
