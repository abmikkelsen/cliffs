{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## function to download and analyse papers from google scholar\n",
        "- This function will do a google scholar search based on a query (food + hazard)\n",
        "- It will attempt to download the first 20 results (mostly through scihub)\n",
        "- Then ChatPDF will check through each pdf and answer your question and find quotes within each pdf\n",
        "\n",
        "You need\n",
        "1. To install PyPaperBot (you can do this in anaconda terminal by typing *pip install PyPaperBot*\n",
        "2. A chatPDF API Key. you can get this by making a chatPDF user and clicking *My Account* on the ChatPDF API website https://www.chatpdf.com/docs/api/backend\n"
      ],
      "metadata": {
        "id": "OQXL6WvaRjgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPaperBot"
      ],
      "metadata": {
        "id": "7LJCcss7SLHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "import glob\n",
        "import PyPaperBot\n",
        "from PyPaperBot import __main__ as p\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "_xutX7eZaM8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnDiieLayiSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTIONS to download and review the papers\n",
        "\n",
        "def download_papers(food, hazard, scholar_pages=[1,2], scholar_results=20, skip_if_folder_exists = True):\n",
        "  ## ----------------------------------- ###\n",
        "    # specify download folder\n",
        "    folder_name = f'{food}_{hazard}'\n",
        "    dwn_dir = os.path.join(os.getcwd(), folder_name)\n",
        "    if os.path.exists(dwn_dir) and skip_if_folder_exists:\n",
        "        pdfs = glob.glob(os.path.join(dwn_dir, '*.pdf'))\n",
        "        print('found %d papers in the folder \"%s\"' %(len(pdfs), folder_name))\n",
        "    else: # not os.path.exists(dwn_dir)\n",
        "        os.mkdir(dwn_dir)\n",
        "        # make query:\n",
        "        query = f'{food}+{hazard}'\n",
        "        #download papers from google scholar\n",
        "        p.start(query=query, scholar_pages=scholar_pages, scholar_results=scholar_results, dwn_dir=dwn_dir, proxy=[])\n",
        "\n",
        "        pdfs = glob.glob(os.path.join(dwn_dir, '*.pdf'))\n",
        "        print('downloaded %d of %d papers' %(len(pdfs), scholar_results))\n",
        "    return pdfs\n",
        "\n",
        "\n",
        "def upload_analyze_papers(food, hazard, pdfs, API_Key, question='default'):\n",
        "    all_results = pd.DataFrame(columns=['filename', 'food', 'hazard', 'quote', 'location', 'page', 'paragraph'])\n",
        "\n",
        "    # Load papers into chatpdf\n",
        "    for file in pdfs:\n",
        "        print(f'loading file \"{os.path.basename(file)}\" ')\n",
        "        files = [('file', ('file', open(file, 'rb'), 'application/octet-stream'))]\n",
        "        headers = {'x-api-key': API_Key}\n",
        "        response = requests.post('https://api.chatpdf.com/v1/sources/add-file', headers=headers, files=files)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            sID = response.json()['sourceId']\n",
        "        else:\n",
        "            print('Status:', response.status_code)\n",
        "            print('Error:', response.text)\n",
        "            continue\n",
        "\n",
        "        # 'Read' papers in chatpdf\n",
        "        headers = {\n",
        "            'x-api-key': API_Key,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        print('analyzing file...')\n",
        "        if question == 'default':\n",
        "            question = f'can you provide 1) a quote from the text about how {hazard} impacts {food}? 2) the location this study takes place 3) the page where this quote is found 4) the paragraph where this quote is found'\n",
        "\n",
        "        data = {\n",
        "            'sourceId': sID,\n",
        "            'messages': [\n",
        "                {\n",
        "                    'role': \"user\",\n",
        "                    'content': question,\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "        response = requests.post(\n",
        "            'https://api.chatpdf.com/v1/chats/message', headers=headers, json=data)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            print('result:', response.json()['content'])\n",
        "            segments = re.split(r'\\d+\\)', response.json()['content'])  # Split the text using regex\n",
        "            if len(segments) >= 4:\n",
        "                quote = segments[0].strip()\n",
        "                location = segments[1].strip()\n",
        "                page = segments[2].strip()\n",
        "                paragraph = segments[3].strip()\n",
        "\n",
        "                # Create a row dictionary for this PDF\n",
        "                row_data = {\n",
        "                    'filename': os.path.basename(file),\n",
        "                    'food': food,\n",
        "                    'hazard': hazard,\n",
        "                    'quote': quote,\n",
        "                    'location': location,\n",
        "                    'page': page,\n",
        "                    'paragraph': paragraph\n",
        "                }\n",
        "\n",
        "                # Append the row data to the results\n",
        "                all_results = pd.concat([all_results, pd.DataFrame([row_data])], ignore_index=True)\n",
        "        else:\n",
        "            print('Status:', response.status_code)\n",
        "            print('Error:', response.text)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def download_read_export(food, hazard, API_Key, scholar_pages=[1,2], scholar_results=20, question='default', skip_if_folder_exists = True):\n",
        "  start_time = time.time() #start timer\n",
        "\n",
        "  pdfs = download_papers(food, hazard, scholar_pages, scholar_results, skip_if_folder_exists)\n",
        "  df = upload_analyze_papers(food, hazard,pdfs, API_Key, question='default')\n",
        "  return df\n",
        "\n",
        "  end_time = time.time() #stop timer\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f'Time taken for \"{food}\" and \"{hazard}\":{elapsed_time:.2f} seconds')\n",
        "\n"
      ],
      "metadata": {
        "id": "fGoTWmpTaEVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and \"read\" the papers\n",
        "- Change food and hazard to any combination and input your API_Key\n",
        "- If you want to change any settings of numbers of pages and number of files to download\n",
        "- You can also specify a question to ask, otherwise it will ask \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
        "\n"
      ],
      "metadata": {
        "id": "K87HXLahRqxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "foods = ['wheat', 'rice', 'tuna', 'apple', 'coffee']\n",
        "hazards = ['drought', 'heatwave', 'warming', 'storm', 'flooding']\n",
        "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
        "scholar_pages = [1,2]\n",
        "scholar_results = 20\n",
        "question = 'default' ## Specify a question in quotes or use the default: \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
        "skip_if_folder_exists = True ## dummy variable, if you have the data downloaded already and dont want to re-download it. defualt=True\n",
        "\n",
        "# Create an empty dataframe to store the results\n",
        "dfall = pd.DataFrame(columns=['food', 'hazard', 'quote', 'location', 'page', 'paragraph'])\n",
        "\n",
        "## Run function across combinations of food and hazard\n",
        "for food in foods:\n",
        "  for hazard in hazards:\n",
        "    df = download_read_export(food, hazard, API_Key, scholar_pages=[1,2], scholar_results=20, question='default', skip_if_folder_exists = True)\n",
        "    dfall = pd.concat([dfall, df], ignore_index=True)\n",
        "\n",
        "# Print the merged dataframe\n",
        "print(dfall)"
      ],
      "metadata": {
        "id": "bjWvV2nDaZDu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "76d47037-71c5-4cb3-d825-e3436dbb554b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-046e05b75b42>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfood\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfoods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mhazard\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhazards\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_read_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhazard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI_Key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscholar_pages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscholar_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_if_folder_exists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdfall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e72283b09151>\u001b[0m in \u001b[0;36mdownload_read_export\u001b[0;34m(food, hazard, API_Key, scholar_pages, scholar_results, question, skip_if_folder_exists)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#start timer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m   \u001b[0mpdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_papers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhazard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscholar_pages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscholar_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_if_folder_exists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupload_analyze_papers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhazard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI_Key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-e72283b09151>\u001b[0m in \u001b[0;36mdownload_papers\u001b[0;34m(food, hazard, scholar_pages, scholar_results, skip_if_folder_exists)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#    print('found %d papers in the folder \"%s\"' %(len(pdfs), folder_name))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#else: # not os.path.exists(dwn_dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwn_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# make query:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{food}+{hazard}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/wheat_heatwave'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfall"
      ],
      "metadata": {
        "id": "aM_4eHO6E5KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QxEKroNCE5Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#####\n",
        "# food systems # climate change\n",
        "# pypaperbot download papers; chatpdf read papers\n",
        "# abm Oct 2023\n",
        "\n",
        "\n",
        "\n",
        "import requests\n",
        "import glob\n",
        "import PyPaperBot\n",
        "from PyPaperBot import __main__ as p\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# FUNCTIONS to download and review the papers\n",
        "\n",
        "def download_papers(food, hazard, scholar_pages=[1,2], scholar_results=20, skip_if_folder_exists = True):\n",
        "  ## ----------------------------------- ###\n",
        "    # specify download folder\n",
        "    folder_name = f'{food}_{hazard}'\n",
        "    dwn_dir = os.path.join(os.getcwd(), folder_name)\n",
        "    if os.path.exists(dwn_dir) and skip_if_folder_exists:\n",
        "        pdfs = glob.glob(os.path.join(dwn_dir, '*.pdf'))\n",
        "        print('found %d papers in the folder \"%s\"' %(len(pdfs), folder_name))\n",
        "    else: # not os.path.exists(dwn_dir)\n",
        "        os.mkdir(dwn_dir)\n",
        "        # make query:\n",
        "        query = f'{food}+{hazard}'\n",
        "        #download papers from google scholar\n",
        "        p.start(query=query, scholar_pages=scholar_pages, scholar_results=scholar_results, dwn_dir=dwn_dir, proxy=[])\n",
        "\n",
        "        pdfs = glob.glob(os.path.join(dwn_dir, '*.pdf'))\n",
        "        print('downloaded %d of %d papers' %(len(pdfs), scholar_results))\n",
        "    return pdfs\n",
        "\n",
        "\n",
        "def upload_analyze_papers(food, hazard, pdfs, API_Key, question='default'):\n",
        "    all_results = pd.DataFrame(columns=['filename', 'food', 'hazard', 'quote', 'location', 'pos/neg', 'how'])\n",
        "\n",
        "    # Load papers into chatpdf\n",
        "    # dummy loop to only upload 12/minute (limit with free plan; to avoid errors)\n",
        "    uploads = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for file in pdfs:\n",
        "        # enter this loop only if number of uploads are 12 or more; if so check if more than 60 sec has passed\n",
        "        if uploads >= 12:\n",
        "            elapsed_time = time.time() - start_time\n",
        "            if elapsed_time < 60:\n",
        "                # if timer is below 60 and uploads are 12, timeout untill the next minute to continue uploads\n",
        "                wait_time = 60 - elapsed_time\n",
        "                print(f'Upload limit reached. Waiting for {wait_time:.2f} seconds...')\n",
        "                time.sleep(wait_time)\n",
        "            uploads = 0  # reset the counter and start a new minute\n",
        "            start_time = time.time()\n",
        "\n",
        "        print(f'loading file \"{os.path.basename(file)}\" ')\n",
        "        files = [('file', ('file', open(file, 'rb'), 'application/octet-stream'))]\n",
        "        headers = {'x-api-key': API_Key}\n",
        "        response = requests.post('https://api.chatpdf.com/v1/sources/add-file', headers=headers, files=files)\n",
        "\n",
        "        uploads += 1 # update the upload counter\n",
        "\n",
        "        #### Then use the paper as input for question\n",
        "        if response.status_code == 200:\n",
        "            sID = response.json()['sourceId']\n",
        "        else:\n",
        "            print('Status:', response.status_code)\n",
        "            print('Error:', response.text)\n",
        "            continue\n",
        "\n",
        "        # 'Read' papers in chatpdf\n",
        "        headers = {\n",
        "            'x-api-key': API_Key,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        print('analyzing file...')\n",
        "        if question == 'default':\n",
        "            question = f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
        "\n",
        "        data = {\n",
        "            'sourceId': sID,\n",
        "            'messages': [\n",
        "                {\n",
        "                    'role': \"user\",\n",
        "                    'content': question,\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "        response = requests.post(\n",
        "            'https://api.chatpdf.com/v1/chats/message', headers=headers, json=data)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            print('result:', response.json()['content'])\n",
        "            results = response.json()['content']\n",
        "            segments = results.split('a)')  # Split the text using regex\n",
        "            if len(segments) >= 4:\n",
        "                quote = segments[0].strip()\n",
        "                location = segments[1].strip()\n",
        "                page = segments[2].strip()\n",
        "                paragraph = segments[3].strip()\n",
        "\n",
        "                # Create a row dictionary for this PDF\n",
        "                row_data = {\n",
        "                    'filename': os.path.basename(file),\n",
        "                    'food': food,\n",
        "                    'hazard': hazard,\n",
        "                    'quote': quote,\n",
        "                    'location': location,\n",
        "                    'pos/neg': page,\n",
        "                    'how': paragraph\n",
        "                }\n",
        "\n",
        "                # Append the row data to the results\n",
        "                all_results = pd.concat([all_results, pd.DataFrame([row_data])], ignore_index=True)\n",
        "        else:\n",
        "            print('Status:', response.status_code)\n",
        "            print('Error:', response.text)\n",
        "        print(\"\\n\")\n",
        "\n",
        "    return all_results\n",
        "\n",
        "def download_read_export(food, hazard, API_Key, scholar_pages=[1,2], scholar_results=20, question='default', skip_if_folder_exists = True):\n",
        "    start_time = time.time() #start timer\n",
        "\n",
        "    pdfs = download_papers(food, hazard, scholar_pages, scholar_results, skip_if_folder_exists)\n",
        "    df = upload_analyze_papers(food, hazard,pdfs, API_Key, question='default')\n",
        "    return df\n",
        "\n",
        "    end_time = time.time() #stop timer\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f'Time taken for \"{food}\" and \"{hazard}\":{elapsed_time:.2f} seconds')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LfDfy4VKE5W2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# Run it\n",
        "\n",
        "foods = ['wheat']#, 'rice', 'tuna', 'apple', 'coffee']\n",
        "hazards = ['heatwave']#, ['drought', 'heatwave', 'warming', 'storm', 'flooding']\n",
        "API_Key = 'sec_6LIDxgLBHBqmhkVam818PYYXqervcPSX' #make a user and get api key from https://www.chatpdf.com/docs/api/backend\n",
        "scholar_pages = [1,2]\n",
        "scholar_results = 5\n",
        "question  = 'default' #f'1a) provide a quote from the text about how {hazard} impacts {food}? 2a) in what region is this study 3a) does {hazard} negatively or positively impact {food} (reply only negatvie/positive) 4a) exactly how is {food} impacted?'\n",
        "\n",
        "# Create an empty dataframe to store the results\n",
        "dfall = pd.DataFrame(columns=['filename', 'food', 'hazard', 'quote', 'location', 'pos/neg', 'how']) ## Specify a question in quotes or use the default: \"How does {hazard} impact {food}? can you provide a quote from the text about this?\"\n",
        "skip_if_folder_exists = True ## dummy variable, if you have the data downloaded already and dont want to re-download it. defualt=True\n",
        "\n",
        "# Create an empty dataframe to store the results\n",
        "#dfall = pd.DataFrame(columns=['food', 'hazard', 'quote', 'location', 'page', 'paragraph'])\n",
        "\n",
        "## Run function across combinations of food and hazard\n",
        "for food in foods:\n",
        "  for hazard in hazards:\n",
        "    df = download_read_export(food, hazard, API_Key, scholar_pages=scholar_pages, scholar_results=scholar_results, question=question, skip_if_folder_exists = True)\n",
        "    dfall = pd.concat([dfall, df], ignore_index=True)\n",
        "\n",
        "# Print the merged dataframe\n",
        "print(dfall)\n",
        "path = os.path.join(os.getcwd(), 'dfall.csv')\n",
        "dfall.to_csv(path)\n"
      ],
      "metadata": {
        "id": "Ce2UkwG4E5aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b73f8f6-cb9c-4ec7-e271-77d09477e0e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: wheat+heatwave\n",
            "\n",
            "Google Scholar page 1 : 5 papers found\n",
            "Searching paper 1 of 5 on Crossref...\n",
            "Searching paper 2 of 5 on Crossref...\n",
            "Searching paper 3 of 5 on Crossref...\n",
            "Searching paper 4 of 5 on Crossref...\n",
            "Searching paper 5 of 5 on Crossref...\n",
            "Papers found on Crossref: 5/5\n",
            "\n",
            "\n",
            "Google Scholar page 2 : 5 papers found\n",
            "Searching paper 1 of 5 on Crossref...\n",
            "Searching paper 2 of 5 on Crossref...\n",
            "Searching paper 3 of 5 on Crossref...\n",
            "Searching paper 4 of 5 on Crossref...\n",
            "Searching paper 5 of 5 on Crossref...\n",
            "Papers found on Crossref: 5/5\n",
            "\n",
            "\n",
            "Using https://sci-hub.ee as Sci-Hub instance\n",
            "Download 1 of 10 -> The spatial-temporal patterns of heatwave hazard impacts on wheat in northern China under extreme climate scenarios\n",
            "Download 2 of 10 -> Substantial increase of compound droughts and heatwaves in wheat growing seasons worldwide\n",
            "Download 3 of 10 -> Can N management affect the magnitude of yield loss due to heat waves in wheat and maize?\n",
            "Download 4 of 10 -> Wheat yield loss attributable to heat waves, drought and water excess at the global, national and subnational scales\n",
            "Download 5 of 10 -> Early heat waves over Italy and their impacts on durum wheat yields\n",
            "Download 6 of 10 -> Elevated atmospheric [CO2] can dramatically increase wheat yields in semi‐arid environments and buffer against heat waves\n",
            "Download 7 of 10 -> Spatio-temporal trend in heat waves over India and its impact assessment on wheat crop\n",
            "Download 8 of 10 -> Impact of heat-wave at high and low VPD on photosynthetic components of wheat and their recovery\n",
            "Download 9 of 10 -> Transient heat waves may affect the photosynthetic capacity of susceptible wheat genotypes due to insufficient photosystem I photoprotection\n",
            "Download 10 of 10 -> Can elevated CO2 buffer the effects of heat waves on wheat in a dryland cropping system?\n",
            "downloaded 9 of 5 papers\n",
            "loading file \"Elevated atmospheric _CO2_ can dramatically increase wheat yields in semi_arid environments and buffer against heat waves.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) \"Because e[CO2] induces stomatal closure (Bernacchi et al., 2007) and therefore reduces canopy cooling, heat stress effects on the canopy could be exacerbated (Wall et al., 2006).\"\n",
            "2a) The study does not specify a particular region.\n",
            "3a) Negative.\n",
            "4a) Heat stress can exacerbate the negative effects on the canopy, reducing canopy cooling and potentially decreasing yields.\n",
            "\n",
            "\n",
            "loading file \"Wheat yield loss attributable to heat waves_ drought and water excess at the global_ national and subnational scales.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) \"The detrimental effect of the heat stress on wheat yield may worsen when coinciding with drought.\" (Page 2)\n",
            "2a) The study does not specify a particular region, as it examines the impact of heat waves, drought, and water excess on wheat yield at global, national, and subnational scales. (Page 2)\n",
            "3a) Negative. (Page 2)\n",
            "4a) Wheat yield is impacted negatively by heat stress, which can worsen when combined with drought. (Page 2)\n",
            "\n",
            "\n",
            "loading file \"Spatio-temporal trend in heat waves over India and its impact assessment on wheat crop.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) \"In March 2010, both the maximum and minimum temperatures over north India, especially in the three major wheat-growing states of Punjab, Haryana and Uttar Pradesh, remained much higher than the normal during the crop season.\" (Page 7)\n",
            "\n",
            "2a) The study focuses on the three major wheat-growing states of north India: Punjab, Haryana, and Uttar Pradesh. (Page 2)\n",
            "\n",
            "3a) Heatwave negatively impacts wheat. (Answer based on the fact that the study analyzes the negative impact of the 2010 heatwave on wheat crop growth and production.)\n",
            "\n",
            "4a) The study analyzes the impact of the 2010 heatwave on wheat crop growth and production in north India. The heatwave negatively impacted the wheat crop, leading to reduced yield, production, and area under cultivation. (Page 7 and 10)\n",
            "\n",
            "\n",
            "loading file \"Impact of heat-wave at high and low VPD on photosynthetic components of wheat and their recovery.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) \"Heat wave will reduce the photosynthetic capacity of wheat mainly by affecting the processes involved in CO2-use.\" \n",
            "2a) The region where this study was conducted is not mentioned in the provided pages. \n",
            "3a) Negative. \n",
            "4a) Wheat is impacted by a reduction in its photosynthetic capacity mainly by affecting the processes involved in CO2-use.\n",
            "\n",
            "\n",
            "loading file \"Can elevated CO2 buffer the effects of heat waves on wheat in a dryland cropping system_.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) \"Heat stress decreases net CO2 assimilation rates resulting in decreased photo-assimilate production as well as reduced dry-matter accumulation and yield.\"\n",
            "2a) The study does not specify a particular region.\n",
            "3a) Heatwave negatively impacts wheat.\n",
            "4a) Wheat is impacted by heatwave through decreased net CO2 assimilation rates, resulting in decreased photo-assimilate production, reduced dry-matter accumulation, and yield.\n",
            "\n",
            "\n",
            "loading file \"The spatial-temporal patterns of heatwave hazard impacts on wheat in northern China under extreme climate scenarios.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) \"The research results of this paper indicate that the impact of heatwaves on wheat in northern China will become more frequent and serious as the Earth becomes warmer.\" \n",
            "2a) The study is focused on northern China. \n",
            "3a) Negative. \n",
            "4a) Heatwaves negatively impact wheat yields.\n",
            "\n",
            "\n",
            "loading file \"Early heat waves over Italy and their impacts on durum wheat yields.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) According to the text, \"These studies substantially agree on the strong effect of extreme temperatures in the reduction of final yields.\"\n",
            "2a) The study focuses on early heat waves that occurred in Italy.\n",
            "3a) Heatwaves negatively impact wheat.\n",
            "4a) Wheat is impacted negatively by heatwaves through a reduction in final yields.\n",
            "\n",
            "\n",
            "loading file \"Transient heat waves may affect the photosynthetic capacity of susceptible wheat genotypes due to insufficient photosystem I photoprotection.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) \"Heat waves (high temperatures for a short time) can significantly reduce the production of grains.\" \n",
            "2a) The study does not specify a region. \n",
            "3a) Negative. \n",
            "4a) Wheat is impacted by a decrease in photosynthetic activity, which can lead to reduced grain production.\n",
            "\n",
            "\n",
            "loading file \"Can N management affect the magnitude of yield loss due to heat waves in wheat and maize_.pdf\" \n",
            "analyzing file...\n",
            "result: 1a) \"Deleterious effects of heat on crop yields are well documented since long time ago\" (Page 2)\n",
            "2a) The study does not specify a particular region.\n",
            "3a) Negative\n",
            "4a) Wheat yield is impacted negatively by heat waves. (Page 2)\n",
            "\n",
            "\n",
            "                                            filename   food    hazard quote  \\\n",
            "0  Elevated atmospheric _CO2_ can dramatically in...  wheat  heatwave     1   \n",
            "1  Wheat yield loss attributable to heat waves_ d...  wheat  heatwave     1   \n",
            "2  Spatio-temporal trend in heat waves over India...  wheat  heatwave     1   \n",
            "3  Impact of heat-wave at high and low VPD on pho...  wheat  heatwave     1   \n",
            "4  Can elevated CO2 buffer the effects of heat wa...  wheat  heatwave     1   \n",
            "5  The spatial-temporal patterns of heatwave haza...  wheat  heatwave     1   \n",
            "6  Early heat waves over Italy and their impacts ...  wheat  heatwave     1   \n",
            "7  Transient heat waves may affect the photosynth...  wheat  heatwave     1   \n",
            "8  Can N management affect the magnitude of yield...  wheat  heatwave     1   \n",
            "\n",
            "                                            location  \\\n",
            "0  \"Because e[CO2] induces stomatal closure (Bern...   \n",
            "1  \"The detrimental effect of the heat stress on ...   \n",
            "2  \"In March 2010, both the maximum and minimum t...   \n",
            "3  \"Heat wave will reduce the photosynthetic capa...   \n",
            "4  \"Heat stress decreases net CO2 assimilation ra...   \n",
            "5  \"The research results of this paper indicate t...   \n",
            "6  According to the text, \"These studies substant...   \n",
            "7  \"Heat waves (high temperatures for a short tim...   \n",
            "8  \"Deleterious effects of heat on crop yields ar...   \n",
            "\n",
            "                                             pos/neg  \\\n",
            "0  The study does not specify a particular region...   \n",
            "1  The study does not specify a particular region...   \n",
            "2  The study focuses on the three major wheat-gro...   \n",
            "3  The region where this study was conducted is n...   \n",
            "4  The study does not specify a particular region...   \n",
            "5        The study is focused on northern China. \\n3   \n",
            "6  The study focuses on early heat waves that occ...   \n",
            "7           The study does not specify a region. \\n3   \n",
            "8  The study does not specify a particular region...   \n",
            "\n",
            "                                                 how  \n",
            "0                                       Negative.\\n4  \n",
            "1                              Negative. (Page 2)\\n4  \n",
            "2  Heatwave negatively impacts wheat. (Answer bas...  \n",
            "3                                      Negative. \\n4  \n",
            "4              Heatwave negatively impacts wheat.\\n4  \n",
            "5                                      Negative. \\n4  \n",
            "6              Heatwaves negatively impact wheat.\\n4  \n",
            "7                                      Negative. \\n4  \n",
            "8                                        Negative\\n4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LiJsYFFJE5eW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPggkaO1xMZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}